    Introduction

ami-071a31a7640172cd9


Work Flow
------------
Registry ---> pull Image --> Container
Registry ---> pull Image --> container --> Login --> Modify -> image Build -> Registry push
Docker file -> image --> Container
Docker file -> Image --> push to Registry --> pull in different DE --> start container


if your container is running then, we should not remove image on which container is running

For Docker Images, there is a default tag => "latest"
if you didn't specify tag while pulling image, then it takes default tag



* Installation
----------------------
docker -v or --version --> to check docker version
yum install docker -y --> to install docker service
systemctl status docker --> to check docker service status
systemctl start docker  --> to start docker service
systemctl stop docker   --> to stop docker service
systemctl restart docker --> to restart docker service
systemctl enable docker  --> to enable docker service

docker info --> to get docker engine info

* Working with Images
---------------------------
<image name>:<tag>

docker images --> to list available docker image from docker Engine
docker images -q --> to list available docker images only id's from docker engine
docker rmi <image id / name> --> to remove particular docker image from DE
docker rmi ${docker images -q} --> to remove all docker images from docker Engine
docker tag <old name> <new name> --> creating duplicate image
docker pull <image name> --> it will pull docker image with tag "latest"
docker pull <image name>:latest --> "    "              "     "
docker pull <image name>:<tag> --> pulling image based on tag specified

* Working with Containers
--------------------------------
docker container ls --> to list docker runiing containers
docker ps --> to list doocker running containers
docker ps -a --> to list all (running & stopped) Containers

docker run --name <con name> -itd <image name> --> to start OS/platform container (dont login while starting)
docker run --name <con name> -it <image name> --> to start OS/platform container (login while starting)
docker run --name <con name> -itd -p <ext port>:<int port> <image name> --> to start service container (dont login while starting)
docker run --name <con name> -it -p <ext port>:<int port> <image name> --> to start service container (login while starting)

example
-------
docker run -d -p 8080:80 nginx

docker exec -it <con name> /bin/<options> --> to login into running container
         options -> bash or sh
docker stop <con name or id> --> to stop docker container
docker start <con name or id> --> to start docker container
docker rm <con name or id> --> to remove stopped container
docker inspect <con name or id> --> to know con info

* Working with Docker Volume
------------------------------
* Docker Volumes are a widely used and useful tool for ensuring data persistence while working in containers
* Docker volumes are file systems mounted on Docker containers to preserve data generated by running container.
* the data doesn't persist when that container no longer exists, and it can be difficult to get the data out of container.


docker volume ls --> to list available volumes
docker volume create <vol name> --> to create docker volume
docker volume rm <vol name> --> to remove volume
docker volume prune --> to remove unused volumes
docker inspect <vol name> --> to know vol info
docker run --name <con name> -itd -v <vol name>:/<folder> <image name> --> to attach vol to container
docker run --name con1 -itd -p 8080:8080 -v logi:/ram httpd -->adding exixting vol to another conatiner

* Working with Docker Networking
------------------------------
docker network ls --> to list available networks
docker network create <n/w name> --> to create docker network
docker network rm <n/w name> --> to remove docker network
docker network prune --> to remove unused n/w
docker inspect <n/w name> --> to know Network info
docker run --name <con name> -itd -p <ext>:<int> --net <nw name> <image name> --> to create con and attach to n/w
docker network connect <nw name> <con namw> --> to connect con to n/w
docker network disconnect <nw name> <con namw> --> to disconnect con from n/w


Sample war file: https://tomcat.apache.org/tomcat-7.0-doc/appdev/sample/sample.war

Dockerfile
------------------
mkdir Dockerfiles
cd Dockerfiles
vi Dockerfile

FROM <image name>:<tag>

MAINTAINER <user id>

RUN <command>

ADD <web url> <con path>

COPY <path of file> <con path>

USER <user name>

EXPOSE <port no>

WORKDIR <path>

CMD ["<name>", "run"]

=== Tomcat Dockerfile ====

FROM tomcat:8.0

MAINTAINER 10101

ADD https://tomcat.apache.org/tomcat-7.0-doc/appdev/sample/sample.war /usr/local/tomcat/webapps/

COPY index.html /usr/local/tomcat/webapps/ROOT/index.html

USER root

EXPOSE 8080

WORKDIR /usr/local/tomcat/webapps/

CMD ["catalina.sh", "run"]


==> to build docker image on Dockerfile
      docker build -t <image name>:<tag>  .


- Login to ECR Registry
    -->  $(aws ecr get-login --no-include-email)

* Docker Compose
-----------------------
till now we have seen about how to start/run single container
if App has n services, each service will run in each container, if you want to start all containers at a time
we need to go for docker compose
---> install docker
---> install docker compose

to check docker compose 
--> docker-compose --version/-v
to download docker compose
--> curl -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
to give execute permission
--> chmod +x /usr/local/bin/docker-compose
For Execution Access
--> sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose

Note:
  Normal --> usr/bin
  Root   --> usr/sbin

mkdir Dockerfiles
vi Dockerfile
   <write here>
vi docker-compose.yml

Syntax for docker-compose
-------------------------
version: '2' --->telling about supported version

services: -->manadatory command and it is nothing but collection of containers
  login:  --->it is a services
    build:  .   --->if image alredy builded it will search for dockerfile in that dir and build image under 
			(or)
=>if we are building images first time the we have provide as follows
	build:
		context: ./path of the folder name
		dockerfile: Dockerfile -->dockerfilename

    container_name: development --->it is just a container name
    ports:			--->giving ports of the container
      -  8080:8080
    environment:		---> supported environment variable for image
      -  spring.profiles.active=development

  adduser:
    build:  .
    depends_on: 
	-login -->telling about depending upon previous started container
	-client
    container_name: uat
    ports:
      -  8090:8080
    environment:
      -  spring.profiles.active=uat
  networks:
	-any network name
	driver:bridge or host or none
  volumes:
	-any volume name
	driver: local
	
-------------------------------------------------------------------------------------------------------------

version: '2'

services:
  login:
    build:  .
    container_name: development
    ports:
      -  8080:8080
    environment:
      -  spring.profiles.active=development

  adduser:
    build:  .
    container_name: uat
    ports:
      -  8090:8080
    environment:
      -  spring.profiles.active=uat
   

docker-compose config --> to check syntax errors
docker-compose up -d
docker-compose down

Docker Swam
-----------------------------------
Open port
2377, 7946, 4789  -- TCP
Launch 3 instances (1 for manager, 2 for nodes)
import docker repo in all instances
  yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
  yum install docker-ce -y
  systemctl start docker
  systemctl enable docker
  systemctl status firewalld
ping 1-1 servers
check docker info

Now On Manager Node
docker swarm init --advertise-addr 65.0.80.154
      after executing, find info
      copy the command, which need to be executed in nodes
      so that nodes will be joining to manager
docker info
    check swam mode (active or any other status & behaving as manager or not)
    docker root dir
docker node ls
Execute above copied command in other instances which are acting as nodes in our system
after executing
docker node ls
docker node inspect <node name>
docker node inspect <node name> --pretty

Some Usefull commands

docker node promote <node> --> promote the node as manager
docker node demote <node> ---> demote the node from Manager role
docker swarm leave  ---> Node leaves the cluster
docker swarm leave --force
docker node rm <node>   --> removes the node from cluster

---- to get tocken ----
docker swarm join-token manager  --> to display token to join nodes


Custom ICMP rule - IPv4

-------------------------------------------------------------------------------

Docker Swarm is a container orchestration tool provided by Docker that allows you to 
manage and deploy containerized applications at scale. It enables you to create and manage 
a cluster of Docker nodes, where each node can run one or more Docker containers. 
Docker Swarm provides built-in features for load balancing, service scaling, rolling updates, and high availability,
 making it easier to manage and maintain containerized applications in a distributed environment.

The main components of Docker Swarm are:

1. **Manager Nodes:** These nodes are responsible for managing the cluster and making 
decisions about the state of services.

2. **Worker Nodes:** These nodes execute the tasks assigned to them by the manager nodes. 
They run the containers and handle the application workload.

Now, let's look at a real-time example to understand the use of Docker Swarm:

**Scenario: Web Application with Docker Swarm**

Suppose you have developed a web application that consists of multiple microservices, 
such as a frontend web server, a backend API, and a database. You want to deploy and run this application 
on a cluster of servers using Docker Swarm.

1. **Initializing the Swarm:**
   You start by creating a Docker Swarm by initializing it on one of your servers, designating it as the manager node.

2. **Adding Worker Nodes:**
   Next, you add several other servers to the Swarm, which will serve as worker nodes. 
These nodes can be physical servers or virtual machines.

3. **Creating Services:**
   You create Docker services for each microservice of your web application. 
A service defines how many replicas (containers) should be running for each microservice. 
You can also specify constraints, such as resource limits or placement preferences.

4. **Load Balancing:**
   Docker Swarm automatically handles load balancing across the worker nodes. 
Requests to the frontend service are distributed evenly across all available containers of that service, 
ensuring efficient use of resources and high availability.

5. **Scaling the Application:**
   As your web application gains popularity and requires more resources, 
you can easily scale your services by increasing the number of replicas. 
Docker Swarm will automatically distribute the workload among the additional containers.

6. **Rolling Updates:**
   When you need to update your web application to a new version, 
Docker Swarm can perform rolling updates. It gradually replaces old containers with new ones, 
ensuring minimal downtime during the update process.

7. **High Availability:**
   Docker Swarm maintains high availability by automatically recovering from node failures. 
If a worker node goes down, the Swarm reschedules the affected containers on other healthy nodes.

By using Docker Swarm, you can simplify the deployment and management of your containerized applications, 
making it easier to scale and maintain them in production environments. It provides the benefits of containerization, 
such as isolation and portability, along with features for orchestrating and managing multi-container applications.







